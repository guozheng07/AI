![image](https://github.com/user-attachments/assets/12747dce-ea30-4da7-88b0-6a0af43f9092)# 模块一 必备大模型基础知识（3讲）
## 01｜大模型的发展：从 GPT-1 到 ChatGPT 的发展历程
1. **GPT 诞生背景**
   ![image](https://github.com/user-attachments/assets/dfff051b-cd61-4946-8bb0-9c0c00311156)

   ![image](https://github.com/user-attachments/assets/1a9ec304-8250-411b-af83-946643f75a79)

2. **GPT 历代版本**
   ![image](https://github.com/user-attachments/assets/220f5b1f-bc44-489b-a8ba-3e1b1b240ef4)

   ![image](https://github.com/user-attachments/assets/edbb471e-4b53-4d23-8620-a539eade09e1)

   ![image](https://github.com/user-attachments/assets/fff01aa5-0ec6-41e4-89db-ebcaa520077f)
   - GPT1：为不同的任务在底层设置不同的网络结构，指定输入和输出格式。
   - GPT2&3：引入 prompt，格式统一为自然语言。
 
3. **ChatGPT 原理简析**
   ![image](https://github.com/user-attachments/assets/8d6220f9-5ef7-48fb-b4e0-0dfc3aa13ce1)

   ![image](https://github.com/user-attachments/assets/7eeb339b-ef32-4e49-a37c-e323cfb6a143)

   ![image](https://github.com/user-attachments/assets/d9c52961-dba5-4e2a-8563-d0969b5a471e)

   ![image](https://github.com/user-attachments/assets/fc798e03-8158-4018-b5ff-74661dfa1325)

   ![image](https://github.com/user-attachments/assets/ea20a40e-fb6a-404f-8df3-20cbd4d0d59b)

4. **ChatGPT 可以做什么？**
   ![image](https://github.com/user-attachments/assets/e5cebbc8-0a9b-4bd2-b089-0ce5fbd67209)

   ![image](https://github.com/user-attachments/assets/393d4c86-1a34-4b92-9d64-01789800c15d)

5. 总结
   ![image](https://github.com/user-attachments/assets/aa201b15-9d63-4899-bbec-47e253b60a75)

## 02｜Prompt 调教指南：大模型的正确打开方式
![image](https://github.com/user-attachments/assets/af911db1-edc8-4db8-8f5a-cab0cf7e1b3f)

![image](https://github.com/user-attachments/assets/e6715e70-058d-4cee-bcb9-809083efba7c)

![image](https://github.com/user-attachments/assets/c31f4a5f-314b-463c-a28b-dcb926e5caf5)

![image](https://github.com/user-attachments/assets/4288eb38-194f-4356-bce6-7ecbc40e0f66)

![image](https://github.com/user-attachments/assets/adfb0569-6f2e-4d35-be11-75560c36e470)

![image](https://github.com/user-attachments/assets/fe7f8d2b-dbe8-4001-8bdc-c0eb288b9977)

![image](https://github.com/user-attachments/assets/aa445fdc-35f5-49a5-8ccd-7870075c374e)

![image](https://github.com/user-attachments/assets/713dbb93-8db3-429d-a110-7280214f21e9)

![image](https://github.com/user-attachments/assets/f4fa7126-a03c-4943-a9d7-634e2623a52f)

![image](https://github.com/user-attachments/assets/41ecf634-a3f1-4ac0-a7d3-1d52bc2f99de)

![image](https://github.com/user-attachments/assets/f1ad88fb-937f-420e-bec2-9350b11a96b7)

![image](https://github.com/user-attachments/assets/e2f416d1-3a6d-42d1-a51a-679f054c89e7)

![image](https://github.com/user-attachments/assets/f6b22d1a-30a0-41df-a63a-89eba221f5d5)

![image](https://github.com/user-attachments/assets/46ebb466-cad1-4c69-9bd1-040cb748b79d)

![image](https://github.com/user-attachments/assets/249923bb-4500-451b-810d-51915b4c624a)

![image](https://github.com/user-attachments/assets/f443a31a-81c0-478d-ae06-ebb4877248e4)

![image](https://github.com/user-attachments/assets/4ebf1e59-655d-4dbb-a36b-3e111481e487)

![image](https://github.com/user-attachments/assets/38e6cd98-a6e0-441d-bde4-0fc800dda6f7)

![image](https://github.com/user-attachments/assets/d2f295e4-c727-449a-992a-e46792e2c243)

![image](https://github.com/user-attachments/assets/16e11c13-909a-4392-832b-79b63e25dec3)

![image](https://github.com/user-attachments/assets/15abb47d-27d6-4542-8fac-50c607ada5a8)

![image](https://github.com/user-attachments/assets/b2810955-168a-41e9-8cac-83591aed08ff)

![image](https://github.com/user-attachments/assets/80b6f6ab-3ddd-428c-9464-e4131d33dd50)

![image](https://github.com/user-attachments/assets/7b2e319e-6cfd-494d-b7f1-12e58beb60df)

## 03｜大模型的基石：认识 Transformer
1. **Transformer 的影响力**
   Transformer 论文：《Attention Is All You Need》

   ![image](https://github.com/user-attachments/assets/c46df11b-151e-4a42-8d7e-659d20c4d5bf)

2. **理解 Transformer 的必备知识**
   机器学习的分类任务：

   ![image](https://github.com/user-attachments/assets/99ecd00f-1668-4745-9a0b-4110b28efa80)
   
   MLP 模型：

   ![image](https://github.com/user-attachments/assets/3bdeda95-019d-428e-be1f-e2e2b460cb89)

   Language 模型：

   ![image](https://github.com/user-attachments/assets/258f2f69-5f4c-41d0-b93f-9013d065a711)
   
4. **Transformer 原理简介**
   ![image](https://github.com/user-attachments/assets/3a7e2739-3f2e-4eb6-9ec8-d0111e4da519)

   ![image](https://github.com/user-attachments/assets/0391bfde-02d3-4396-aab1-a7cd97282888)
   - attention 机制使模型更关注**欧拉**这个输入词汇。
  
   ![image](https://github.com/user-attachments/assets/e9aece8c-b4cb-4143-a0c3-95c33f6d5774)
   
5. 总结
   ![image](https://github.com/user-attachments/assets/dbd12c19-0218-477a-b591-10176e25a512)

# 模块二 大模型微调技巧攻略（6讲）
## 04｜检索增强生成（RAG）：如何让大模型回答更准确？
1. **检索增强生成（RAG）出现的背景**
   ![image](https://github.com/user-attachments/assets/43e8fd44-1df5-40b2-ae0d-2c275487bbcf)

   ![image](https://github.com/user-attachments/assets/00c742e0-3161-4c56-9c89-e196b642b1df)

2. **RAG 技术方案介绍**
    ![image](https://github.com/user-attachments/assets/9a418d4f-4992-43c2-b1fe-67599b2796c4)
   - 准备阶段
     - load：将搜集到的文档记载进来，可能是 pdf、word 和 txt 格式（推荐 txt，并且最好经过清洗）
     - split：文档切块
     - embed：通过向量模型，将切换文档向量化
     - store：存储到向量数据库
   - 调用阶段
     - question：问题向量化
     - retrieve：从向量数据库中检索出相关片段，拼接到 prompt 中（原始问题+相关片段）
     - LLM：大模型根据上下文知识做回答

3. **RAG 案例演示**
   ![image](https://github.com/user-attachments/assets/2a195b5b-ea3d-457e-9776-4da57f425229)

   ![image](https://github.com/user-attachments/assets/f05da0f7-ace5-47df-b723-26a05ee3b16f)

   ![image](https://github.com/user-attachments/assets/a724116e-5f88-4462-8ddb-7fab530e6a44)

   ![image](https://github.com/user-attachments/assets/8d237902-2fcd-4538-bd11-88e115080059)

   ![image](https://github.com/user-attachments/assets/4a2d258f-432d-49f1-9702-ff144fbe7c1a)

   ![image](https://github.com/user-attachments/assets/39e4aa62-65d9-4312-8b13-ea49f27b1f60)

   ![image](https://github.com/user-attachments/assets/380111e3-0bab-42b4-858b-de300abfc854)

   ![image](https://github.com/user-attachments/assets/cd4f1abf-d00d-49f9-be43-168c990ec6c7)
   - context 即为检索到的相似片段。

4. 总结
![image](https://github.com/user-attachments/assets/25e40774-e02d-4bc1-ae42-363a22ce01ec)

## 05｜模型评估：如何准确测评大模型的能力？
1. **封闭式问题测评**
   ![image](https://github.com/user-attachments/assets/98dab077-f678-4cb6-a98b-99a2eab4752e)
   - 数据集：https://huggingface.co/datasets/t1annnnn/Chinese_sentimentAnalyze?row=0

   ![image](https://github.com/user-attachments/assets/87380953-0bf9-4c51-8694-8bf4e4895242)

   ![image](https://github.com/user-attachments/assets/c40b9f2d-2dea-4c95-9087-db023b051140)

   ![image](https://github.com/user-attachments/assets/fd631ba7-422b-4826-a2bd-532dfd2c1bc2)

   ![image](https://github.com/user-attachments/assets/c030be95-f64d-48bd-9c4c-f1a017cdc6ae)

2. **开放式问题测评**
   ![image](https://github.com/user-attachments/assets/7f1c331c-1ede-45b5-a9b1-1bb29fe65682)
   - 数据集：https://github.com/morecry/CharacterEval?tab=readme-ov-file

   ![image](https://github.com/user-attachments/assets/12292dc1-988c-4257-b543-8534306ddfd3)

   ![image](https://github.com/user-attachments/assets/ba31bdb6-c882-4456-9f37-98e984731882)

   ![image](https://github.com/user-attachments/assets/a3a3854f-b25e-4d28-9c7b-dfef14019942)

   ![image](https://github.com/user-attachments/assets/9240fb7d-1fb0-4ebf-9cc0-b09fd0080fa2)

3. 总结
   ![image](https://github.com/user-attachments/assets/0baea5ab-4808-40aa-9c58-fb2dc75db6ff)

4. 课后练习
   选择任意大模型，测评在中文情感分类数据集上的效果。
   - 数据集：https://huggingface.co/datasets/t1annnnn/Chinese_sentimentAnalyze/viewer/default/test（数据集较大，可以取 test 数据集前 100条 进行测评）

## 06｜微调数据准备：如何构造高质量微调数据？
1. **微调数据简介**
   ![image](https://github.com/user-attachments/assets/dae02ab6-8d08-4a7a-ac02-b9bbc73719aa)
   - **用平台来微调**，只需要关注对话使用的自然语言，平台会帮忙做微调数据格式的转化

   ![image](https://github.com/user-attachments/assets/261060f3-6a79-41bd-bb9b-448ca11da1ae)
   - **用模型来微调**，需要关注模型的微调数据格式
   - [Llama 3 模型微调说明](https://www.llama.com/docs/model-cards-and-prompt-formats/meta-llama-3/)
  
   ![image](https://github.com/user-attachments/assets/2c7aefbe-019e-4c90-8583-1ccface45b0a)

   ![image](https://github.com/user-attachments/assets/712cb01d-04cc-45a7-88ab-c95b28b8d55c)

2. **如何构造微调数据？**
   ![image](https://github.com/user-attachments/assets/f778b125-26df-40c8-8fdc-1c7d0020463e)
   - [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)
   - 下面重点介绍微调数据的合成

   ![image](https://github.com/user-attachments/assets/0ae3089c-ad2a-4b06-b01b-9f7bc745bb44)
   - [Code Llama: Open Foundation Models for Code](https://arxiv.org/abs/2308.12950)
  
   ![image](https://github.com/user-attachments/assets/8f3cb913-dc49-4843-81ac-b809b9f6b270)
   - [WizardLM: Empowering Large Language Models to Follow Complex Instructions](https://arxiv.org/abs/2304.12244)

   ![image](https://github.com/user-attachments/assets/a68f28b5-fd49-47e5-a137-2f3f81f15701)

   
3. **高质量微调数据构建案例**
   ![image](https://github.com/user-attachments/assets/98e988bb-f56a-4277-9844-53aded35c8b7)

   ![image](https://github.com/user-attachments/assets/0210c4f4-14dc-4805-aa24-e23e658a6753)

   ![image](https://github.com/user-attachments/assets/89312834-b8ce-4d5b-9805-6c2a71b67b57)

4. 总结
   ![image](https://github.com/user-attachments/assets/a095922e-a433-415a-867c-b8b5a2fa15a0)

   ![image](https://github.com/user-attachments/assets/3569f7e7-8fff-4be7-a884-68d9b5ae66a2)

## 07｜全量参数微调：如何让大模型完成特定领域任务？
1. **微调原理简介**
   ![image](https://github.com/user-attachments/assets/26479507-68ed-4cb5-acae-d9e55725c559)

   ![image](https://github.com/user-attachments/assets/861d1393-1a7b-4008-b02e-75dd64b95d90)

   ![image](https://github.com/user-attachments/assets/7f78e6d0-f9c6-41da-8aed-3c8aad601219)

2. **LLM的微调**
   ![image](https://github.com/user-attachments/assets/31739aff-751b-417f-955b-183dd20782ce)
   - https://github.com/morecry/CharacterEval?tab=readme-ov-file

   ![image](https://github.com/user-attachments/assets/bd375893-4579-41bb-b83e-476d3192ba3f)

   ![image](https://github.com/user-attachments/assets/806406fd-b260-46c5-b1e9-3c0ba8cf363b)

   ![image](https://github.com/user-attachments/assets/69cb830b-24f6-4bd8-97cd-c5dad0238ca1)

   ![image](https://github.com/user-attachments/assets/a20cdb62-8d24-472b-b058-cbc90e141883)

   ![image](https://github.com/user-attachments/assets/67c3a6bc-ccbc-472e-a31a-665ca60edad1)

3. **模型 SFT 训练流程**
   ![image](https://github.com/user-attachments/assets/65a675a1-fe9b-48d8-9d89-3720d8431310)

   ![image](https://github.com/user-attachments/assets/79448bdf-f77f-4bc8-8fac-4d486948ce25)

   ![image](https://github.com/user-attachments/assets/88f90c3b-7d3d-4f2b-95f2-13c814c3c8f1)

   ![image](https://github.com/user-attachments/assets/9d0dea62-f479-4930-b935-5af4d4ace395)

4. 总结
   ![image](https://github.com/user-attachments/assets/b3035f5d-7b63-4166-abc3-0af29186ae0f)

   ![image](https://github.com/user-attachments/assets/38b0418e-7455-4207-8c1a-4ee01abdb713)

## 08｜LoRA 微调：如何高效微调大模型？

## 09｜Post-Pretrain：如何进一步注入领域知识？

# 模块三 大模型微调实践演练（3讲）
## 10｜案例1：如何微调一个英语口语练习大模型？

## 11｜案例2：如何微调一个作文批改大模型？

## 12｜案例3：如何微调一个角色扮演大模型？
